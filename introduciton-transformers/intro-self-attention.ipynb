{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45fd742",
   "metadata": {},
   "source": [
    "# A First Look at Self-Attention\n",
    "\n",
    "## Why Self-Attention Helps With Meaning\n",
    "\n",
    "Consider the following review:\n",
    "\n",
    "> **“The movie was *not* good, but the soundtrack was amazing.”**\n",
    "\n",
    "A simple bag-of-words classifier will see both *good* and *amazing* (positive) and probably predict a positive sentiment, missing the negation “not.”  \n",
    "\n",
    "Self-attention can discover that \"not\" modifies \"good\" while leaving \"amazing\" untouched.\n",
    "\n",
    "### 1. Tokenise the sentence\n",
    "\n",
    "| position | token |\n",
    "|:-------:|-------|\n",
    "| 0 | The |\n",
    "| 1 | movie |\n",
    "| 2 | was |\n",
    "| 3 | **not** |\n",
    "| 4 | **good** |\n",
    "| 5 | , |\n",
    "| 6 | but |\n",
    "| 7 | the |\n",
    "| 8 | soundtrack |\n",
    "| 9 | was |\n",
    "|10 | **amazing** |\n",
    "|11 | . |\n",
    "\n",
    "Each token is mapped to a small vector (embedding).  \n",
    "For illustration imagine every token is already a 4-D vector.  \n",
    "The exact numbers are not important; they are learned during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9b989",
   "metadata": {},
   "source": [
    "### 2. Compute attention scores (conceptually)\n",
    "\n",
    "Focus on the token at position 4, **“good.”**\n",
    "\n",
    "* Query $q_{good}$ is compared with every key $k_j$.\n",
    "* Large dot products mean higher relevance.\n",
    "* After scaling and the softmax, we obtain a **weight** for each other token.\n",
    "\n",
    "Suppose the softmax gives (rounded):\n",
    "\n",
    "| key token $j$ | weight $w_{4j}$ |\n",
    "|-----------------|-------------------|\n",
    "| The             | 0.01 |\n",
    "| movie           | 0.02 |\n",
    "| was (1st)       | 0.03 |\n",
    "| **not**         | **0.55** |\n",
    "| **good**        | 0.10 |\n",
    "| ,               | 0.02 |\n",
    "| but             | 0.05 |\n",
    "| the             | 0.02 |\n",
    "| soundtrack      | 0.03 |\n",
    "| was (2nd)       | 0.05 |\n",
    "| amazing         | 0.11 |\n",
    "| .               | 0.01 |\n",
    "\n",
    "*The model assigns more than half of the total weight to “not,” capturing the local negation, and a moderate share to “amazing,” which influences the overall sentiment.*\n",
    "\n",
    "\n",
    "### 3. Weighted sum of value vectors\n",
    "\n",
    "$$\n",
    "\\text{output}(\\text{good})\n",
    "      =\\sum_{j=0}^{11} w_{4j}\\,v_j .\n",
    "$$\n",
    "\n",
    "Because $w_{4,3}=0.55$ is large, the output vector encodes that **“good” is negated**.  \n",
    "\n",
    "Later layers (or a classifier head) can use this context-rich vector to predict a negative contribution from *“not good,”* while recognising the strong positive signal from *“amazing.”*\n",
    "\n",
    "### 4. Key points \n",
    "\n",
    "* **Context matters.** Self-attention lets every token look at the entire sentence, so “not” can influence “good.”  \n",
    "* **Parallel computation.** Unlike an RNN, all tokens are processed at once, which is faster and handles long sentences gracefully.  \n",
    "* **Dynamic meaning.** The same word can mean something different in another sentence; the attention pattern adapts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838d52f",
   "metadata": {},
   "source": [
    "## Toy Example on the sentence  \n",
    "\n",
    "> **“The movie was *not* good, but the soundtrack was amazing.”**\n",
    "\n",
    "1. **Start with an input embedding**  \n",
    "   For every token $i$ in the sentence you have a fixed-size vector  \n",
    "   $$\n",
    "     x_i \\in \\mathbb{R}^{d_{\\text{model}}}.\n",
    "   $$\n",
    "\n",
    "2. **Project that same vector three different ways**  \n",
    "   The self-attention layer contains three trainable weight matrices  \n",
    "   $W_Q,\\,W_K,\\,W_V \\in \\mathbb{R}^{d_{\\text{model}}\\times d_k}$.\n",
    "   It computes  \n",
    "   $$\n",
    "     q_i = W_Q x_i, \\qquad\n",
    "     k_i = W_K x_i, \\qquad\n",
    "     v_i = W_V x_i .\n",
    "   $$\n",
    "\n",
    "3. **Interpretation**  \n",
    "   * **Query $q_i$**: “What am I looking for in the other tokens?”  \n",
    "   * **Key $k_i$**: “How well do I match what others might look for?”  \n",
    "   * **Value $v_i$**: “The information I will contribute if I am selected.”\n",
    "\n",
    "   During training the matrices learn to make queries and keys align for\n",
    "   linguistically relevant relations (negation, subject–verb agreement,\n",
    "   coreference, and so on).\n",
    "\n",
    "\n",
    "\n",
    "To keep arithmetic tiny we use **2-dimensional** vectors and *hand-craft* them\n",
    "for the three important words; all others are zeros.\n",
    "\n",
    "| token (index) | query $q_i$ | key $k_i$ | value $v_i$ |\n",
    "|--------------|--------------|-------------|---------------|\n",
    "| not (3)      | $[1,1]$    | $[1,1]$   | $[1,0]$ |\n",
    "| good (4)     | $[0,1]$    | $[0,1]$   | $[0,1]$ |\n",
    "| amazing (10) | $[1,0]$    | $[1,0]$   | $[1,1]$ |\n",
    "| all others   | $[0,0]$    | $[0,0]$   | $[0,0]$ |\n",
    "\n",
    "### Attention weights **from “good” to every token**\n",
    "\n",
    "1. Dot products of $q_{\\text{good}}=[0,1]$ with every $k_j$:\n",
    "\n",
    "   * $q\\cdot k_{3} = 1$ → token 3 (“not”)\n",
    "   * $q\\cdot k_{4} = 1$ → token 4 (“good” itself)\n",
    "   * all other dot products = 0  \n",
    "\n",
    "2. Scale by $\\sqrt{d_k}=\\sqrt{2}\\approx1.41$  \n",
    "   non-zero scores become $1/1.41 = 0.707$.\n",
    "\n",
    "3. Softmax across 12 tokens:\n",
    "\n",
    "   $$\n",
    "   w_{4,3}=w_{4,4}\\approx0.14,\\quad\n",
    "   w_{4,j\\neq3,4}\\approx0.07 .\n",
    "   $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722329ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights from 'good':\n",
      "[0.07 0.07 0.07 0.14 0.14 0.07 0.07 0.07 0.07 0.07 0.07 0.07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 12 tokens × 2-dimensional toy vectors\n",
    "Q = np.zeros((12, 2), dtype=\"float32\")\n",
    "K = np.zeros_like(Q)\n",
    "V = np.zeros_like(Q)\n",
    "\n",
    "# encode three words with non-zero vectors\n",
    "Q[3] = K[3] = [1, 1]   # token 3 = \"not\"\n",
    "Q[4] = K[4] = [0, 1]   # token 4 = \"good\"   ← the query we will inspect\n",
    "Q[10] = K[10]= [1, 0]  # token10 = \"amazing\"\n",
    "V[:] = K[:]            # values = keys for clarity\n",
    "\n",
    "dk = K.shape[-1]\n",
    "scores   = Q[4] @ K.T / np.sqrt(dk)          # dot products from “good” to all keys\n",
    "weights  = np.exp(scores) / np.exp(scores).sum()\n",
    "\n",
    "print(\"Attention weights from 'good':\")\n",
    "print(np.round(weights, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb70d1",
   "metadata": {},
   "source": [
    "where  \n",
    "\n",
    "* **$Q$** = queries (one per input position)  \n",
    "* **$K$** = keys (one per input position)  \n",
    "* **$V$** = values (one per input position)  \n",
    "* $d_k$ = dimensionality of the keys (used for scaling).\n",
    "\n",
    " \n",
    "\n",
    "## A Toy Example (3-word mini-sentence)\n",
    "\n",
    "Assume the sentence *“She **did** not”* has already been converted to three 2-dimensional vectors (for clarity the numbers are tiny integers):\n",
    "\n",
    "| token | $q_i$ | $k_i$ | $v_i$ |\n",
    "|-------|-------|-------|-------|\n",
    "| She   | $\\begin{bmatrix}1\\\\0\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\0\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ |\n",
    "| did   | $\\begin{bmatrix}0\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}0\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}0\\\\2\\end{bmatrix}$ |\n",
    "| not   | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}2\\\\1\\end{bmatrix}$ |\n",
    "\n",
    "### 1. Compute the *raw* attention scores  \n",
    "For each pair $(q_i,k_j)$ take the dot product:\n",
    "\n",
    "|  | **She** | **did** | **not** |\n",
    "|---|--------|--------|--------|\n",
    "| **She** | $1\\cdot1+0\\cdot0 = 1$ | $1\\cdot0+0\\cdot1 = 0$ | $1\\cdot1+0\\cdot1 = 1$ |\n",
    "| **did** | $0\\cdot1+1\\cdot0 = 0$ | $0\\cdot0+1\\cdot1 = 1$ | $0\\cdot1+1\\cdot1 = 1$ |\n",
    "| **not** | $1\\cdot1+1\\cdot0 = 1$ | $1\\cdot0+1\\cdot1 = 1$ | $1\\cdot1+1\\cdot1 = 2$ |\n",
    "\n",
    "### 2. Scale and apply $\\operatorname{softmax}$ row-wise  \n",
    "With $d_k=2$, divide by $\\sqrt{2}\\approx1.41$, then apply $\\operatorname{softmax}$ to each row  \n",
    "(result rounded to two decimals):\n",
    "\n",
    "|  | She | did | not |\n",
    "|---|-----|-----|-----|\n",
    "| **She** | 0.42 | 0.16 | 0.42 |\n",
    "| **did** | 0.16 | 0.42 | 0.42 |\n",
    "| **not** | 0.26 | 0.26 | 0.48 |\n",
    "\n",
    "These are the **attention weights**.\n",
    "\n",
    "### 3. Weighted sum of the values  \n",
    "For the first token “She”:\n",
    "\n",
    "$$\n",
    "\\text{output}(\\text{She}) =\n",
    "0.42\\,v_{\\text{She}} \\;+\\; 0.16\\,v_{\\text{did}} \\;+\\; 0.42\\,v_{\\text{not}}\n",
    "= 0.42\\!\\begin{bmatrix}1\\\\1\\end{bmatrix}\n",
    "  +0.16\\!\\begin{bmatrix}0\\\\2\\end{bmatrix}\n",
    "  +0.42\\!\\begin{bmatrix}2\\\\1\\end{bmatrix}\n",
    "= \\begin{bmatrix}1.26\\\\1.26\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The same happens for “did” and “not”.  \n",
    "Each output vector now **blends information from the entire sequence**, with larger weights on more relevant words.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2302e9",
   "metadata": {},
   "source": [
    "| index | token              | weight | interpretation                              |\n",
    "|:----:|--------------------|:------:|---------------------------------------------|\n",
    "| 0    | The                | 0.07   | almost ignored                              |\n",
    "| 1    | movie              | 0.07   | almost ignored                              |\n",
    "| 2    | was (first)        | 0.07   | almost ignored                              |\n",
    "| 3    | **not**            | **0.14** | most relevant external word (negation)      |\n",
    "| 4    | **good** (itself)  | **0.14** | self-focus helps preserve the base meaning  |\n",
    "| 5    | ,                  | 0.07   | punctuation, little influence               |\n",
    "| 6    | but                | 0.07   | discourse marker, low weight here           |\n",
    "| 7    | the                | 0.07   | almost ignored                              |\n",
    "| 8    | soundtrack         | 0.07   | almost ignored                              |\n",
    "| 9    | was (second)       | 0.07   | almost ignored                              |\n",
    "| 10   | amazing            | 0.07   | small influence, sentiment elsewhere        |\n",
    "| 11   | .                  | 0.07   | negligible influence                        |\n",
    "\n",
    "Key observations:\n",
    "\n",
    "* The two highest weights (0.14) fall on **“not”** and **“good”** itself.  \n",
    "  The model therefore combines the negation signal with the word it negates.\n",
    "* Every other token receives the baseline weight of about \\(1/12 \\approx 0.08\\),\n",
    "  meaning they contribute very little to the representation of “good.”\n",
    "\n",
    "In a fully trained model you would expect an even sharper focus on **“not”**\n",
    "and a near-zero weight on punctuation or stop-words. \n",
    "\n",
    "The principle is: weights tell you **which words the model uses as\n",
    "evidence when forming the contextual meaning of the current word.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850131c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with label 1: [  10   11  135  208  222  300  349  401  427  448  462  478  482  488\n",
      "  493  564  570  585  590  607  620  675  723  800  831  884  933  973\n",
      " 1043 1108 1115 1137 1151 1166 1215 1389 1496 1513 1598 1638 1647 1680\n",
      " 1688 1808 1830 1857 1893 1901 1903 1922 1944 2080 2087 2121 2130 2199\n",
      " 2269 2335 2391 2443 2444 2508 2531 2571 2595 2642 2666 2674 2693 2718\n",
      " 2804 2856 2867 2890 2985 2993 3025 3036 3094 3163 3213 3365 3418 3496\n",
      " 3504 3523 3539 3547 3556 3560 3588 3729 3761 3808 3824 3831 3934 3939\n",
      " 4043 4084 4092 4128 4148 4184 4221 4290 4294 4360 4579 4630 4685 4723\n",
      " 4729 4743 4751 4786 4821 5048 5133 5150 5163 5165 5278 5294 5316 5378\n",
      " 5440 5518 5544 5572 5802 5902 5918 5972 6146 6172 6232 6373 6428 6470\n",
      " 6594 6611 6634 6673 6751 6849 7018 7035 7101 7214 7307 7311 7330 7417\n",
      " 7482 7552 7565 7587 7599 7765 7849 7850 7888 7895 7898 7909 7911 7966]\n",
      "Their label values: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Sentences with label 1:\n",
      " [[ 0 16  5 ... 43 32  2]\n",
      " [ 0  2 40 ... 36 39 12]\n",
      " [ 0 37 46 ...  3 34 13]\n",
      " ...\n",
      " [ 0  3 11 ... 29 17 37]\n",
      " [ 0 19 47 ... 17 20  7]\n",
      " [ 0 23 35 ... 36 39 43]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TinySelfAttention\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TinySelfAttention\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">464</span> │ tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attn           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)]  │            │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ self_attn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_12         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ get_item_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tokens (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │        \u001b[38;5;34m464\u001b[0m │ tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attn           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m),    │        \u001b[38;5;34m288\u001b[0m │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)]  │            │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_16 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ self_attn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m16\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_12         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ get_item_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777</span> (3.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m777\u001b[0m (3.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777</span> (3.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m777\u001b[0m (3.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\n",
      "Attention weights  (sample 0 · head 0):\n",
      "[[0.1883 0.1169 0.1175 0.2313 0.1093 0.1051 0.1316]\n",
      " [0.1746 0.1253 0.1261 0.2016 0.1197 0.1166 0.136 ]\n",
      " [0.1726 0.1262 0.1268 0.1992 0.1209 0.1179 0.1365]\n",
      " [0.1573 0.1354 0.1355 0.1681 0.1323 0.1308 0.1406]\n",
      " [0.1668 0.1298 0.1303 0.1866 0.1254 0.123  0.1381]\n",
      " [0.1669 0.1297 0.1303 0.1868 0.1253 0.1229 0.1381]\n",
      " [0.1703 0.1278 0.1286 0.193  0.1229 0.1201 0.1373]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0.  Reproducibility\n",
    "# ------------------------------------------------------------------\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Synthetic data  (NumPy arrays only!)\n",
    "# ------------------------------------------------------------------\n",
    "VOCAB_SIZE  = 51         # reserve 0 for [CLS]\n",
    "SEQ_LEN     = 6          # NOT counting [CLS]\n",
    "NUM_SAMPLES = 8_000          # instead of 64\n",
    "EPOCHS = 3                   # fewer epochs are fine with more data\n",
    "\n",
    "tokens_np = np.random.randint(1, VOCAB_SIZE, size=(NUM_SAMPLES, SEQ_LEN))\n",
    "tokens_np = np.concatenate(\n",
    "    [np.zeros((NUM_SAMPLES, 1), dtype=int), tokens_np], axis=1   # prepend [CLS]\n",
    ")                                   # shape (N, 7)\n",
    "\n",
    "labels_np = (tokens_np[:, 3] == 42).astype(\"float32\")\n",
    "\n",
    "# indices where the label is 1\n",
    "pos_idx = np.where(labels_np == 1)[0]\n",
    "\n",
    "print(\"Indices with label 1:\", pos_idx)\n",
    "\n",
    "# show the actual label values (all 1.0) to double-check\n",
    "print(\"Their label values:\", labels_np[pos_idx])\n",
    "\n",
    "# if you also want to see the sentences themselves:\n",
    "print(\"Sentences with label 1:\\n\", tokens_np[pos_idx])\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Positional-embedding block\n",
    "# ------------------------------------------------------------------\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab, d_model, max_len, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.tok = layers.Embedding(vocab,   d_model, name=\"tok_emb\")\n",
    "        self.pos = layers.Embedding(max_len, d_model, name=\"pos_emb\")\n",
    "\n",
    "    def call(self, tok_ids):                       # (B, L)\n",
    "        L = tf.shape(tok_ids)[1]\n",
    "        pos_ids = tf.range(L)                      # 0 … L-1\n",
    "        return self.tok(tok_ids) + self.pos(pos_ids)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Model\n",
    "# ------------------------------------------------------------------\n",
    "D_MODEL   = 8\n",
    "NUM_HEADS = 1\n",
    "KEY_DIM   = D_MODEL // NUM_HEADS\n",
    "\n",
    "inp      = layers.Input((SEQ_LEN + 1,), dtype=\"int32\", name=\"tokens\")\n",
    "emb      = PositionalEmbedding(VOCAB_SIZE, D_MODEL, SEQ_LEN + 1,\n",
    "                               name=\"embed\")(inp)\n",
    "\n",
    "attn_out, attn_scores = layers.MultiHeadAttention(\n",
    "        num_heads=NUM_HEADS,\n",
    "        key_dim=KEY_DIM,\n",
    "        output_shape=D_MODEL,\n",
    "        name=\"self_attn\")(emb, emb, return_attention_scores=True)\n",
    "\n",
    "x        = layers.LayerNormalization(epsilon=1e-6, name=\"ln\")(emb + attn_out)\n",
    "cls_vec  = x[:, 0, :]                           # [CLS]\n",
    "logits   = layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(cls_vec)\n",
    "\n",
    "model = Model(inp, logits, name=\"TinySelfAttention\")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Train\n",
    "# ------------------------------------------------------------------\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((tokens_np, labels_np))\n",
    "      .shuffle(NUM_SAMPLES)\n",
    "      .batch(16)\n",
    ")\n",
    "model.fit(train_ds, epochs=EPOCHS, verbose=0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  Attention matrix for the first sample\n",
    "# ------------------------------------------------------------------\n",
    "attn_extractor = Model(inp, attn_scores)       # model that outputs only A\n",
    "A = attn_extractor.predict(tokens_np[:1])      # shape (1, 1, 7, 7)\n",
    "\n",
    "print(\"\\nAttention weights  (sample 0 · head 0):\")\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(A[0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "397c26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-0: [ 0 45 48  1  4  4 40]\n",
      "Token at pos-3: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Model output for sample-0: 0.00041184496\n",
      "Sentence-idx: [ 0 16  5 42 43 32  2]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "0.99762386\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence-0:\", tokens_np[0])\n",
    "print(\"Token at pos-3:\", tokens_np[0, 3])\n",
    "pred = model.predict(tokens_np[:1])[0, 0]\n",
    "print(\"Model output for sample-0:\", pred)   # should be ≪ 0.5\n",
    "\n",
    "idx = np.where(labels_np == 1)[0][0]   # first positive sample\n",
    "print(\"Sentence-idx:\", tokens_np[idx])\n",
    "print(model.predict(tokens_np[idx:idx+1])[0, 0])  # should be ≫ 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311af02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
