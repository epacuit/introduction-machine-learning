{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45fd742",
   "metadata": {},
   "source": [
    "# A First Look at Self-Attention\n",
    "\n",
    "## Why Self-Attention Helps With Meaning\n",
    "\n",
    "Consider the following review:\n",
    "\n",
    "> **“The movie was *not* good, but the soundtrack was amazing.”**\n",
    "\n",
    "A simple bag-of-words classifier will see both *good* and *amazing* (positive) and probably predict a positive sentiment, missing the negation “not.”  \n",
    "\n",
    "Self-attention can discover that \"not\" modifies \"good\" while leaving \"amazing\" untouched.\n",
    "\n",
    "### 1. Tokenise the sentence\n",
    "\n",
    "| position | token |\n",
    "|:-------:|-------|\n",
    "| 0 | The |\n",
    "| 1 | movie |\n",
    "| 2 | was |\n",
    "| 3 | **not** |\n",
    "| 4 | **good** |\n",
    "| 5 | , |\n",
    "| 6 | but |\n",
    "| 7 | the |\n",
    "| 8 | soundtrack |\n",
    "| 9 | was |\n",
    "|10 | **amazing** |\n",
    "|11 | . |\n",
    "\n",
    "Each token is mapped to a small vector (embedding).  \n",
    "For illustration imagine every token is already a 4-D vector.  \n",
    "The exact numbers are not important; they are learned during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9b989",
   "metadata": {},
   "source": [
    "### 2. Compute attention scores (conceptually)\n",
    "\n",
    "Focus on the token at position 4, **“good.”**\n",
    "\n",
    "* Query $q_{good}$ is compared with every key $k_j$.\n",
    "* Large dot products mean higher relevance.\n",
    "* After scaling and the softmax, we obtain a **weight** for each other token.\n",
    "\n",
    "Suppose the softmax gives (rounded):\n",
    "\n",
    "| key token $j$ | weight $w_{4j}$ |\n",
    "|-----------------|-------------------|\n",
    "| The             | 0.01 |\n",
    "| movie           | 0.02 |\n",
    "| was (1st)       | 0.03 |\n",
    "| **not**         | **0.55** |\n",
    "| **good**        | 0.10 |\n",
    "| ,               | 0.02 |\n",
    "| but             | 0.05 |\n",
    "| the             | 0.02 |\n",
    "| soundtrack      | 0.03 |\n",
    "| was (2nd)       | 0.05 |\n",
    "| amazing         | 0.11 |\n",
    "| .               | 0.01 |\n",
    "\n",
    "*The model assigns more than half of the total weight to “not,” capturing the local negation, and a moderate share to “amazing,” which influences the overall sentiment.*\n",
    "\n",
    "\n",
    "### 3. Weighted sum of value vectors\n",
    "\n",
    "$$\n",
    "\\text{output}(\\text{good})\n",
    "      =\\sum_{j=0}^{11} w_{4j}\\,v_j .\n",
    "$$\n",
    "\n",
    "Because $w_{4,3}=0.55$ is large, the output vector encodes that **“good” is negated**.  \n",
    "\n",
    "Later layers (or a classifier head) can use this context-rich vector to predict a negative contribution from *“not good,”* while recognising the strong positive signal from *“amazing.”*\n",
    "\n",
    "### 4. Key points \n",
    "\n",
    "* **Context matters.** Self-attention lets every token look at the entire sentence, so “not” can influence “good.”  \n",
    "* **Parallel computation.** Unlike an RNN, all tokens are processed at once, which is faster and handles long sentences gracefully.  \n",
    "* **Dynamic meaning.** The same word can mean something different in another sentence; the attention pattern adapts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe2c08",
   "metadata": {},
   "source": [
    "### Query **Q**, Key **K**, and Value **V**\n",
    "\n",
    "Let  \n",
    "\n",
    "* $X \\in \\mathbb{R}^{n \\times d_{\\text{model}}}$ be the matrix whose rows are the token-embedding vectors after positional encoding  \n",
    "  $\\bigl[x_1^{\\top};\\,x_2^{\\top};\\,\\dots;\\,x_n^{\\top}\\bigr]$.\n",
    "\n",
    "For **each attention head** $h$ the model keeps three learned weight matrices  \n",
    "\n",
    "$$\n",
    "W_Q^{(h)},\\; W_K^{(h)},\\; W_V^{(h)} \\in \\mathbb{R}^{d_{\\text{model}}\\times d_k}.\n",
    "$$\n",
    "\n",
    "Multiplying the embedding matrix by those weights yields  \n",
    "\n",
    "$$\n",
    "\\boxed{Q^{(h)} \\;=\\; X\\,W_Q^{(h)}}, \\qquad\n",
    "\\boxed{K^{(h)} \\;=\\; X\\,W_K^{(h)}}, \\qquad\n",
    "\\boxed{V^{(h)} \\;=\\; X\\,W_V^{(h)}}.\n",
    "$$\n",
    "\n",
    "* **Shape:** each of $Q^{(h)}, K^{(h)}, V^{(h)}$ is $n \\times d_k$.  \n",
    "  (One $d_k$-dimensional row per token.)\n",
    "* **Rows:** $q_i,\\;k_i,\\;v_i$ — the *query*, *key*, and *value* vectors for token $i$.\n",
    "\n",
    "\n",
    "| Symbol |   Intuitive meaning |\n",
    "|--------|---------------------------------|\n",
    "| $q_i$  | “What does **this** token need or look for?” |\n",
    "| $k_j$  | “What attributes does token *j* offer to others?” |\n",
    "| $v_j$  |  “The information token *j* will contribute if it is attended to.” |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78617a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Masked attention weights FROM ‘good’ (index 4)\n",
      "  → The          w = 0.07\n",
      "  → movie        w = 0.07\n",
      "  → was          w = 0.07\n",
      "  → not          w = 0.62\n",
      "  → good         w = 0.15\n",
      "  → ,            w = 0.00\n",
      "  → but          w = 0.00\n",
      "  → the          w = 0.00\n",
      "  → soundtrack   w = 0.00\n",
      "  → was          w = 0.00\n",
      "  → amazing      w = 0.00\n",
      "  → .            w = 0.00\n",
      "\n",
      "Resulting context vector for 'good': [0.62393289 0.15168853]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Token list – indices are handy for debugging\n",
    "# ---------------------------------------------------------------------\n",
    "tokens = [\"The\", \"movie\", \"was\", \"not\", \"good\", \",\", \"but\",\n",
    "          \"the\", \"soundtrack\", \"was\", \"amazing\", \".\"]\n",
    "\n",
    "n_tokens, d = len(tokens), 2                # d_model = 2\n",
    "Q = np.zeros((n_tokens, d))\n",
    "K = np.zeros((n_tokens, d))\n",
    "V = np.zeros((n_tokens, d))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Hand-crafted vectors for the three special words\n",
    "# ---------------------------------------------------------------------\n",
    "special_qk = {3: [1, 1],      # “not”\n",
    "              4: [0, 1],      # “good”\n",
    "             10: [1, 0]}      # “amazing”\n",
    "\n",
    "special_v  = {3: [1, 0],\n",
    "              4: [0, 1],\n",
    "             10: [1, 1]}\n",
    "\n",
    "for idx, vec in special_qk.items():\n",
    "    Q[idx] = K[idx] = vec\n",
    "\n",
    "for idx, vec in special_v.items():\n",
    "    V[idx] = vec\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Scaled dot-product attention  (decoder style → add causal mask)\n",
    "# ---------------------------------------------------------------------\n",
    "scores = Q @ K.T                           # (n_tokens × n_tokens)\n",
    "scores /= np.sqrt(d)                       # scale by √d_k\n",
    "\n",
    "# ---- causal (look-ahead) mask ----\n",
    "mask = np.triu(np.ones_like(scores, dtype=bool), k=1)  # j > i region\n",
    "scores[mask] = -1e9                      # −∞ ⇒ 0 after softmax\n",
    "\n",
    "# Softmax row by row\n",
    "exp_scores = np.exp(scores)\n",
    "weights = exp_scores / exp_scores.sum(axis=-1, keepdims=True)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Attention output = weights · V\n",
    "# ---------------------------------------------------------------------\n",
    "outputs = weights @ V                      # (n_tokens × d)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) Inspect the row that corresponds to the *query* word “good”\n",
    "# ---------------------------------------------------------------------\n",
    "idx_good = 4\n",
    "print(f\"\\nMasked attention weights FROM ‘{tokens[idx_good]}’ (index {idx_good})\")\n",
    "for j, w in enumerate(weights[idx_good]):\n",
    "    print(f\"  → {tokens[j]:<11s}  w = {w:.2f}\")\n",
    "\n",
    "print(\"\\nResulting context vector for 'good':\", outputs[idx_good])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb70d1",
   "metadata": {},
   "source": [
    "where  \n",
    "\n",
    "* **$Q$** = queries (one per input position)  \n",
    "* **$K$** = keys (one per input position)  \n",
    "* **$V$** = values (one per input position)  \n",
    "* $d_k$ = dimensionality of the keys (used for scaling).\n",
    "\n",
    " \n",
    "\n",
    "## A Toy Example (3-word mini-sentence)\n",
    "\n",
    "Assume the sentence *“She **did** not”* has already been converted to three 2-dimensional vectors (for clarity the numbers are tiny integers):\n",
    "\n",
    "| token | $q_i$ | $k_i$ | $v_i$ |\n",
    "|-------|-------|-------|-------|\n",
    "| She   | $\\begin{bmatrix}1\\\\0\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\0\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ |\n",
    "| did   | $\\begin{bmatrix}0\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}0\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}0\\\\2\\end{bmatrix}$ |\n",
    "| not   | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}2\\\\1\\end{bmatrix}$ |\n",
    "\n",
    "### 1. Compute the *raw* attention scores  \n",
    "For each pair $(q_i,k_j)$ take the dot product:\n",
    "\n",
    "|  | **She** | **did** | **not** |\n",
    "|---|--------|--------|--------|\n",
    "| **She** | $1\\cdot1+0\\cdot0 = 1$ | $1\\cdot0+0\\cdot1 = 0$ | $1\\cdot1+0\\cdot1 = 1$ |\n",
    "| **did** | $0\\cdot1+1\\cdot0 = 0$ | $0\\cdot0+1\\cdot1 = 1$ | $0\\cdot1+1\\cdot1 = 1$ |\n",
    "| **not** | $1\\cdot1+1\\cdot0 = 1$ | $1\\cdot0+1\\cdot1 = 1$ | $1\\cdot1+1\\cdot1 = 2$ |\n",
    "\n",
    "### 2. Scale and apply $\\operatorname{softmax}$ row-wise  \n",
    "With $d_k=2$, divide by $\\sqrt{2}\\approx1.41$, then apply $\\operatorname{softmax}$ to each row  \n",
    "(result rounded to two decimals):\n",
    "\n",
    "|  | She | did | not |\n",
    "|---|-----|-----|-----|\n",
    "| **She** | 0.42 | 0.16 | 0.42 |\n",
    "| **did** | 0.16 | 0.42 | 0.42 |\n",
    "| **not** | 0.26 | 0.26 | 0.48 |\n",
    "\n",
    "These are the **attention weights**.\n",
    "\n",
    "### 3. Weighted sum of the values  \n",
    "For the first token “She”:\n",
    "\n",
    "$$\n",
    "\\text{output}(\\text{She}) =\n",
    "0.42\\,v_{\\text{She}} \\;+\\; 0.16\\,v_{\\text{did}} \\;+\\; 0.42\\,v_{\\text{not}}\n",
    "= 0.42\\!\\begin{bmatrix}1\\\\1\\end{bmatrix}\n",
    "  +0.16\\!\\begin{bmatrix}0\\\\2\\end{bmatrix}\n",
    "  +0.42\\!\\begin{bmatrix}2\\\\1\\end{bmatrix}\n",
    "= \\begin{bmatrix}1.26\\\\1.26\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The same happens for “did” and “not”.  \n",
    "Each output vector now **blends information from the entire sequence**, with larger weights on more relevant words.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850131c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with label 1: [  10   11  135  208  222  300  349  401  427  448  462  478  482  488\n",
      "  493  564  570  585  590  607  620  675  723  800  831  884  933  973\n",
      " 1043 1108 1115 1137 1151 1166 1215 1389 1496 1513 1598 1638 1647 1680\n",
      " 1688 1808 1830 1857 1893 1901 1903 1922 1944 2080 2087 2121 2130 2199\n",
      " 2269 2335 2391 2443 2444 2508 2531 2571 2595 2642 2666 2674 2693 2718\n",
      " 2804 2856 2867 2890 2985 2993 3025 3036 3094 3163 3213 3365 3418 3496\n",
      " 3504 3523 3539 3547 3556 3560 3588 3729 3761 3808 3824 3831 3934 3939\n",
      " 4043 4084 4092 4128 4148 4184 4221 4290 4294 4360 4579 4630 4685 4723\n",
      " 4729 4743 4751 4786 4821 5048 5133 5150 5163 5165 5278 5294 5316 5378\n",
      " 5440 5518 5544 5572 5802 5902 5918 5972 6146 6172 6232 6373 6428 6470\n",
      " 6594 6611 6634 6673 6751 6849 7018 7035 7101 7214 7307 7311 7330 7417\n",
      " 7482 7552 7565 7587 7599 7765 7849 7850 7888 7895 7898 7909 7911 7966]\n",
      "Their label values: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Sentences with label 1:\n",
      " [[ 0 16  5 ... 43 32  2]\n",
      " [ 0  2 40 ... 36 39 12]\n",
      " [ 0 37 46 ...  3 34 13]\n",
      " ...\n",
      " [ 0  3 11 ... 29 17 37]\n",
      " [ 0 19 47 ... 17 20  7]\n",
      " [ 0 23 35 ... 36 39 43]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TinySelfAttention\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TinySelfAttention\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">464</span> │ tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attn           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)]  │            │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ self_attn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_13         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ get_item_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tokens (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │        \u001b[38;5;34m464\u001b[0m │ tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attn           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m),    │        \u001b[38;5;34m288\u001b[0m │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)]  │            │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_17 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ self_attn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m16\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_13         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ get_item_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777</span> (3.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m777\u001b[0m (3.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777</span> (3.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m777\u001b[0m (3.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Attention weights  (sample 0 · head 0):\n",
      "[[0.1647 0.1109 0.1221 0.2472 0.1152 0.1147 0.1252]\n",
      " [0.1619 0.1164 0.126  0.2272 0.1201 0.1197 0.1287]\n",
      " [0.1633 0.1138 0.1241 0.2369 0.1177 0.1173 0.127 ]\n",
      " [0.1579 0.1227 0.1307 0.2048 0.1258 0.1254 0.1327]\n",
      " [0.1636 0.1132 0.1237 0.2389 0.1172 0.1168 0.1266]\n",
      " [0.161  0.1178 0.127  0.2224 0.1213 0.1209 0.1296]\n",
      " [0.1604 0.1188 0.1277 0.2188 0.1222 0.1218 0.1302]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0.  Reproducibility\n",
    "# ------------------------------------------------------------------\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Synthetic data  (NumPy arrays only!)\n",
    "# ------------------------------------------------------------------\n",
    "VOCAB_SIZE  = 51   \n",
    "SEQ_LEN     = 6      \n",
    "NUM_SAMPLES = 8_000   \n",
    "EPOCHS = 3          \n",
    "\n",
    "tokens_np = np.random.randint(1, VOCAB_SIZE, size=(NUM_SAMPLES, SEQ_LEN))\n",
    "tokens_np = np.concatenate(\n",
    "    [np.zeros((NUM_SAMPLES, 1), dtype=int), tokens_np], axis=1   # prepend [CLS]\n",
    ")                                   # shape (N, 7)\n",
    "\n",
    "labels_np = (tokens_np[:, 3] == 42).astype(\"float32\")\n",
    "\n",
    "# indices where the label is 1\n",
    "pos_idx = np.where(labels_np == 1)[0]\n",
    "\n",
    "print(\"Indices with label 1:\", pos_idx)\n",
    "\n",
    "# show the actual label values (all 1.0) to double-check\n",
    "print(\"Their label values:\", labels_np[pos_idx])\n",
    "\n",
    "# if you also want to see the sentences themselves:\n",
    "print(\"Sentences with label 1:\\n\", tokens_np[pos_idx])\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Positional-embedding block\n",
    "# ------------------------------------------------------------------\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab, d_model, max_len, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.tok = layers.Embedding(vocab,   d_model, name=\"tok_emb\")\n",
    "        self.pos = layers.Embedding(max_len, d_model, name=\"pos_emb\")\n",
    "\n",
    "    def call(self, tok_ids):                       # (B, L)\n",
    "        L = tf.shape(tok_ids)[1]\n",
    "        pos_ids = tf.range(L)                      # 0 … L-1\n",
    "        return self.tok(tok_ids) + self.pos(pos_ids)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Model\n",
    "# ------------------------------------------------------------------\n",
    "D_MODEL   = 8\n",
    "NUM_HEADS = 1\n",
    "KEY_DIM   = D_MODEL // NUM_HEADS\n",
    "\n",
    "inp      = layers.Input((SEQ_LEN + 1,), dtype=\"int32\", name=\"tokens\")\n",
    "emb      = PositionalEmbedding(VOCAB_SIZE, D_MODEL, SEQ_LEN + 1,\n",
    "                               name=\"embed\")(inp)\n",
    "\n",
    "attn_out, attn_scores = layers.MultiHeadAttention(\n",
    "        num_heads=NUM_HEADS,\n",
    "        key_dim=KEY_DIM,\n",
    "        output_shape=D_MODEL,\n",
    "        name=\"self_attn\")(emb, emb, return_attention_scores=True)\n",
    "\n",
    "x        = layers.LayerNormalization(epsilon=1e-6, name=\"ln\")(emb + attn_out)\n",
    "cls_vec  = x[:, 0, :]                           # [CLS]\n",
    "logits   = layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(cls_vec)\n",
    "\n",
    "model = Model(inp, logits, name=\"TinySelfAttention\")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Train\n",
    "# ------------------------------------------------------------------\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((tokens_np, labels_np))\n",
    "      .shuffle(NUM_SAMPLES)\n",
    "      .batch(16)\n",
    ")\n",
    "model.fit(train_ds, epochs=EPOCHS, verbose=0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  Attention matrix for the first sample\n",
    "# ------------------------------------------------------------------\n",
    "attn_extractor = Model(inp, attn_scores)       # model that outputs only A\n",
    "A = attn_extractor.predict(tokens_np[:1])      # shape (1, 1, 7, 7)\n",
    "\n",
    "print(\"\\nAttention weights  (sample 0 · head 0):\")\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(A[0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "397c26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-0: [ 0 45 48  1  4  4 40]\n",
      "Token at pos-3: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Model output for sample-0: 0.00061386\n",
      "Sentence-idx: [ 0 16  5 42 43 32  2]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "0.99714214\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence-0:\", tokens_np[0])\n",
    "print(\"Token at pos-3:\", tokens_np[0, 3])\n",
    "pred = model.predict(tokens_np[:1])[0, 0]\n",
    "print(\"Model output for sample-0:\", pred)   # should be ≪ 0.5\n",
    "\n",
    "idx = np.where(labels_np == 1)[0][0]   # first positive sample\n",
    "print(\"Sentence-idx:\", tokens_np[idx])\n",
    "print(model.predict(tokens_np[idx:idx+1])[0, 0])  # should be ≫ 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311af02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
