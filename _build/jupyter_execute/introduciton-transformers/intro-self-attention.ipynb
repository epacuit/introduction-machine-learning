{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45fd742",
   "metadata": {},
   "source": [
    "# A First Look at Self-Attention\n",
    "\n",
    "## Why Self-Attention Helps With Meaning\n",
    "\n",
    "Consider the following review:\n",
    "\n",
    "> **“The movie was *not* good, but the soundtrack was amazing.”**\n",
    "\n",
    "A simple bag-of-words classifier will see both *good* and *amazing* (positive) and probably predict a positive sentiment, missing the negation “not.”  \n",
    "\n",
    "Self-attention can discover that \"not\" modifies \"good\" while leaving \"amazing\" untouched.\n",
    "\n",
    "### 1. Tokenise the sentence\n",
    "\n",
    "| position | token |\n",
    "|:-------:|-------|\n",
    "| 0 | The |\n",
    "| 1 | movie |\n",
    "| 2 | was |\n",
    "| 3 | **not** |\n",
    "| 4 | **good** |\n",
    "| 5 | , |\n",
    "| 6 | but |\n",
    "| 7 | the |\n",
    "| 8 | soundtrack |\n",
    "| 9 | was |\n",
    "|10 | **amazing** |\n",
    "|11 | . |\n",
    "\n",
    "Each token is mapped to a small vector (embedding).  \n",
    "For illustration imagine every token is already a 4-D vector.  \n",
    "The exact numbers are not important; they are learned during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec9b989",
   "metadata": {},
   "source": [
    "### 2. Compute attention scores (conceptually)\n",
    "\n",
    "Focus on the token at position 4, **“good.”**\n",
    "\n",
    "* Query $q_{good}$ is compared with every key $k_j$.\n",
    "* Large dot products mean higher relevance.\n",
    "* After scaling and the softmax, we obtain a **weight** for each other token.\n",
    "\n",
    "Suppose the softmax gives (rounded):\n",
    "\n",
    "| key token $j$ | weight $w_{4j}$ |\n",
    "|-----------------|-------------------|\n",
    "| The             | 0.01 |\n",
    "| movie           | 0.02 |\n",
    "| was (1st)       | 0.03 |\n",
    "| **not**         | **0.55** |\n",
    "| **good**        | 0.10 |\n",
    "| ,               | 0.02 |\n",
    "| but             | 0.05 |\n",
    "| the             | 0.02 |\n",
    "| soundtrack      | 0.03 |\n",
    "| was (2nd)       | 0.05 |\n",
    "| amazing         | 0.11 |\n",
    "| .               | 0.01 |\n",
    "\n",
    "*The model assigns more than half of the total weight to “not,” capturing the local negation, and a moderate share to “amazing,” which influences the overall sentiment.*\n",
    "\n",
    "\n",
    "### 3. Weighted sum of value vectors\n",
    "\n",
    "$$\n",
    "\\text{output}(\\text{good})\n",
    "      =\\sum_{j=0}^{11} w_{4j}\\,v_j .\n",
    "$$\n",
    "\n",
    "Because $w_{4,3}=0.55$ is large, the output vector encodes that **“good” is negated**.  \n",
    "\n",
    "Later layers (or a classifier head) can use this context-rich vector to predict a negative contribution from *“not good,”* while recognising the strong positive signal from *“amazing.”*\n",
    "\n",
    "### 4. Key points \n",
    "\n",
    "* **Context matters.** Self-attention lets every token look at the entire sentence, so “not” can influence “good.”  \n",
    "* **Parallel computation.** Unlike an RNN, all tokens are processed at once, which is faster and handles long sentences gracefully.  \n",
    "* **Dynamic meaning.** The same word can mean something different in another sentence; the attention pattern adapts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838d52f",
   "metadata": {},
   "source": [
    "## Toy Example on the sentence  \n",
    "\n",
    "> **“The movie was *not* good, but the soundtrack was amazing.”**\n",
    "\n",
    "1. **Start with an input embedding**  \n",
    "   For every token $i$ in the sentence you have a fixed-size vector  \n",
    "   $$\n",
    "     x_i \\in \\mathbb{R}^{d_{\\text{model}}}.\n",
    "   $$\n",
    "\n",
    "2. **Project that same vector three different ways**  \n",
    "   The self-attention layer contains three trainable weight matrices  \n",
    "   $W_Q,\\,W_K,\\,W_V \\in \\mathbb{R}^{d_{\\text{model}}\\times d_k}$.\n",
    "   It computes  \n",
    "   $$\n",
    "     q_i = W_Q x_i, \\qquad\n",
    "     k_i = W_K x_i, \\qquad\n",
    "     v_i = W_V x_i .\n",
    "   $$\n",
    "\n",
    "3. **Interpretation**  \n",
    "   * **Query $q_i$**: “What am I looking for in the other tokens?”  \n",
    "   * **Key $k_i$**: “How well do I match what others might look for?”  \n",
    "   * **Value $v_i$**: “The information I will contribute if I am selected.”\n",
    "\n",
    "   During training the matrices learn to make queries and keys align for\n",
    "   linguistically relevant relations (negation, subject–verb agreement,\n",
    "   coreference, and so on).\n",
    "\n",
    "\n",
    "\n",
    "To keep arithmetic tiny we use **2-dimensional** vectors and *hand-craft* them\n",
    "for the three important words; all others are zeros.\n",
    "\n",
    "| token (index) | query $q_i$ | key $k_i$ | value $v_i$ |\n",
    "|--------------|--------------|-------------|---------------|\n",
    "| not (3)      | $[1,1]$    | $[1,1]$   | $[1,0]$ |\n",
    "| good (4)     | $[0,1]$    | $[0,1]$   | $[0,1]$ |\n",
    "| amazing (10) | $[1,0]$    | $[1,0]$   | $[1,1]$ |\n",
    "| all others   | $[0,0]$    | $[0,0]$   | $[0,0]$ |\n",
    "\n",
    "### Attention weights **from “good” to every token**\n",
    "\n",
    "1. Dot products of $q_{\\text{good}}=[0,1]$ with every $k_j$:\n",
    "\n",
    "   * $q\\cdot k_{3} = 1$ → token 3 (“not”)\n",
    "   * $q\\cdot k_{4} = 1$ → token 4 (“good” itself)\n",
    "   * all other dot products = 0  \n",
    "\n",
    "2. Scale by $\\sqrt{d_k}=\\sqrt{2}\\approx1.41$  \n",
    "   non-zero scores become $1/1.41 = 0.707$.\n",
    "\n",
    "3. Softmax across 12 tokens:\n",
    "\n",
    "   $$\n",
    "   w_{4,3}=w_{4,4}\\approx0.14,\\quad\n",
    "   w_{4,j\\neq3,4}\\approx0.07 .\n",
    "   $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722329ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights from 'good':\n",
      "[0.07 0.07 0.07 0.14 0.14 0.07 0.07 0.07 0.07 0.07 0.07 0.07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 12 tokens × 2-dimensional toy vectors\n",
    "Q = np.zeros((12, 2), dtype=\"float32\")\n",
    "K = np.zeros_like(Q)\n",
    "V = np.zeros_like(Q)\n",
    "\n",
    "# encode three words with non-zero vectors\n",
    "Q[3] = K[3] = [1, 1]   # token 3 = \"not\"\n",
    "Q[4] = K[4] = [0, 1]   # token 4 = \"good\"   ← the query we will inspect\n",
    "Q[10] = K[10]= [1, 0]  # token10 = \"amazing\"\n",
    "V[:] = K[:]            # values = keys for clarity\n",
    "\n",
    "dk = K.shape[-1]\n",
    "scores   = Q[4] @ K.T / np.sqrt(dk)          # dot products from “good” to all keys\n",
    "weights  = np.exp(scores) / np.exp(scores).sum()\n",
    "\n",
    "print(\"Attention weights from 'good':\")\n",
    "print(np.round(weights, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb70d1",
   "metadata": {},
   "source": [
    "where  \n",
    "\n",
    "* **$Q$** = queries (one per input position)  \n",
    "* **$K$** = keys (one per input position)  \n",
    "* **$V$** = values (one per input position)  \n",
    "* $d_k$ = dimensionality of the keys (used for scaling).\n",
    "\n",
    " \n",
    "\n",
    "## A Toy Example (3-word mini-sentence)\n",
    "\n",
    "Assume the sentence *“She **did** not”* has already been converted to three 2-dimensional vectors (for clarity the numbers are tiny integers):\n",
    "\n",
    "| token | $q_i$ | $k_i$ | $v_i$ |\n",
    "|-------|-------|-------|-------|\n",
    "| She   | $\\begin{bmatrix}1\\\\0\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\0\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ |\n",
    "| did   | $\\begin{bmatrix}0\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}0\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}0\\\\2\\end{bmatrix}$ |\n",
    "| not   | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}1\\\\1\\end{bmatrix}$ | $\\begin{bmatrix}2\\\\1\\end{bmatrix}$ |\n",
    "\n",
    "### 1. Compute the *raw* attention scores  \n",
    "For each pair $(q_i,k_j)$ take the dot product:\n",
    "\n",
    "|  | **She** | **did** | **not** |\n",
    "|---|--------|--------|--------|\n",
    "| **She** | $1\\cdot1+0\\cdot0 = 1$ | $1\\cdot0+0\\cdot1 = 0$ | $1\\cdot1+0\\cdot1 = 1$ |\n",
    "| **did** | $0\\cdot1+1\\cdot0 = 0$ | $0\\cdot0+1\\cdot1 = 1$ | $0\\cdot1+1\\cdot1 = 1$ |\n",
    "| **not** | $1\\cdot1+1\\cdot0 = 1$ | $1\\cdot0+1\\cdot1 = 1$ | $1\\cdot1+1\\cdot1 = 2$ |\n",
    "\n",
    "### 2. Scale and apply $\\operatorname{softmax}$ row-wise  \n",
    "With $d_k=2$, divide by $\\sqrt{2}\\approx1.41$, then apply $\\operatorname{softmax}$ to each row  \n",
    "(result rounded to two decimals):\n",
    "\n",
    "|  | She | did | not |\n",
    "|---|-----|-----|-----|\n",
    "| **She** | 0.42 | 0.16 | 0.42 |\n",
    "| **did** | 0.16 | 0.42 | 0.42 |\n",
    "| **not** | 0.26 | 0.26 | 0.48 |\n",
    "\n",
    "These are the **attention weights**.\n",
    "\n",
    "### 3. Weighted sum of the values  \n",
    "For the first token “She”:\n",
    "\n",
    "$$\n",
    "\\text{output}(\\text{She}) =\n",
    "0.42\\,v_{\\text{She}} \\;+\\; 0.16\\,v_{\\text{did}} \\;+\\; 0.42\\,v_{\\text{not}}\n",
    "= 0.42\\!\\begin{bmatrix}1\\\\1\\end{bmatrix}\n",
    "  +0.16\\!\\begin{bmatrix}0\\\\2\\end{bmatrix}\n",
    "  +0.42\\!\\begin{bmatrix}2\\\\1\\end{bmatrix}\n",
    "= \\begin{bmatrix}1.26\\\\1.26\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The same happens for “did” and “not”.  \n",
    "Each output vector now **blends information from the entire sequence**, with larger weights on more relevant words.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2302e9",
   "metadata": {},
   "source": [
    "| index | token              | weight | interpretation                              |\n",
    "|:----:|--------------------|:------:|---------------------------------------------|\n",
    "| 0    | The                | 0.07   | almost ignored                              |\n",
    "| 1    | movie              | 0.07   | almost ignored                              |\n",
    "| 2    | was (first)        | 0.07   | almost ignored                              |\n",
    "| 3    | **not**            | **0.14** | most relevant external word (negation)      |\n",
    "| 4    | **good** (itself)  | **0.14** | self-focus helps preserve the base meaning  |\n",
    "| 5    | ,                  | 0.07   | punctuation, little influence               |\n",
    "| 6    | but                | 0.07   | discourse marker, low weight here           |\n",
    "| 7    | the                | 0.07   | almost ignored                              |\n",
    "| 8    | soundtrack         | 0.07   | almost ignored                              |\n",
    "| 9    | was (second)       | 0.07   | almost ignored                              |\n",
    "| 10   | amazing            | 0.07   | small influence, sentiment elsewhere        |\n",
    "| 11   | .                  | 0.07   | negligible influence                        |\n",
    "\n",
    "Key observations:\n",
    "\n",
    "* The two highest weights (0.14) fall on **“not”** and **“good”** itself.  \n",
    "  The model therefore combines the negation signal with the word it negates.\n",
    "* Every other token receives the baseline weight of about \\(1/12 \\approx 0.08\\),\n",
    "  meaning they contribute very little to the representation of “good.”\n",
    "\n",
    "In a fully trained model you would expect an even sharper focus on **“not”**\n",
    "and a near-zero weight on punctuation or stop-words. \n",
    "\n",
    "The principle is: weights tell you **which words the model uses as\n",
    "evidence when forming the contextual meaning of the current word.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850131c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with label 1: [  10   11  135  208  222  300  349  401  427  448  462  478  482  488\n",
      "  493  564  570  585  590  607  620  675  723  800  831  884  933  973\n",
      " 1043 1108 1115 1137 1151 1166 1215 1389 1496 1513 1598 1638 1647 1680\n",
      " 1688 1808 1830 1857 1893 1901 1903 1922 1944 2080 2087 2121 2130 2199\n",
      " 2269 2335 2391 2443 2444 2508 2531 2571 2595 2642 2666 2674 2693 2718\n",
      " 2804 2856 2867 2890 2985 2993 3025 3036 3094 3163 3213 3365 3418 3496\n",
      " 3504 3523 3539 3547 3556 3560 3588 3729 3761 3808 3824 3831 3934 3939\n",
      " 4043 4084 4092 4128 4148 4184 4221 4290 4294 4360 4579 4630 4685 4723\n",
      " 4729 4743 4751 4786 4821 5048 5133 5150 5163 5165 5278 5294 5316 5378\n",
      " 5440 5518 5544 5572 5802 5902 5918 5972 6146 6172 6232 6373 6428 6470\n",
      " 6594 6611 6634 6673 6751 6849 7018 7035 7101 7214 7307 7311 7330 7417\n",
      " 7482 7552 7565 7587 7599 7765 7849 7850 7888 7895 7898 7909 7911 7966]\n",
      "Their label values: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Sentences with label 1:\n",
      " [[ 0 16  5 ... 43 32  2]\n",
      " [ 0  2 40 ... 36 39 12]\n",
      " [ 0 37 46 ...  3 34 13]\n",
      " ...\n",
      " [ 0  3 11 ... 29 17 37]\n",
      " [ 0 19 47 ... 17 20  7]\n",
      " [ 0 23 35 ... 36 39 43]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 07:33:28.021067: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2025-04-29 07:33:28.021089: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 96.00 GB\n",
      "2025-04-29 07:33:28.021093: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 36.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745926408.021104 15681900 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1745926408.021126 15681900 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TinySelfAttention\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TinySelfAttention\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">464</span> │ tokens[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attn           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)]  │            │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ self_attn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ln[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tokens (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embed               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │        \u001b[38;5;34m464\u001b[0m │ tokens[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attn           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m),    │        \u001b[38;5;34m288\u001b[0m │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)]  │            │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ self_attn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ln                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m16\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ ln[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ classifier (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m9\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777</span> (3.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m777\u001b[0m (3.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777</span> (3.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m777\u001b[0m (3.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 07:33:28.571476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 4.  Train\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     78\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     79\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((tokens_np, labels_np))\n\u001b[1;32m     80\u001b[0m       \u001b[38;5;241m.\u001b[39mshuffle(NUM_SAMPLES)\n\u001b[1;32m     81\u001b[0m       \u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     82\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# 5.  Attention matrix for the first sample\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     88\u001b[0m attn_extractor \u001b[38;5;241m=\u001b[39m Model(inp, attn_scores)       \u001b[38;5;66;03m# model that outputs only A\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0.  Reproducibility\n",
    "# ------------------------------------------------------------------\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Synthetic data  (NumPy arrays only!)\n",
    "# ------------------------------------------------------------------\n",
    "VOCAB_SIZE  = 51         # reserve 0 for [CLS]\n",
    "SEQ_LEN     = 6          # NOT counting [CLS]\n",
    "NUM_SAMPLES = 8_000          # instead of 64\n",
    "EPOCHS = 3                   # fewer epochs are fine with more data\n",
    "\n",
    "tokens_np = np.random.randint(1, VOCAB_SIZE, size=(NUM_SAMPLES, SEQ_LEN))\n",
    "tokens_np = np.concatenate(\n",
    "    [np.zeros((NUM_SAMPLES, 1), dtype=int), tokens_np], axis=1   # prepend [CLS]\n",
    ")                                   # shape (N, 7)\n",
    "\n",
    "labels_np = (tokens_np[:, 3] == 42).astype(\"float32\")\n",
    "\n",
    "# indices where the label is 1\n",
    "pos_idx = np.where(labels_np == 1)[0]\n",
    "\n",
    "print(\"Indices with label 1:\", pos_idx)\n",
    "\n",
    "# show the actual label values (all 1.0) to double-check\n",
    "print(\"Their label values:\", labels_np[pos_idx])\n",
    "\n",
    "# if you also want to see the sentences themselves:\n",
    "print(\"Sentences with label 1:\\n\", tokens_np[pos_idx])\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Positional-embedding block\n",
    "# ------------------------------------------------------------------\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, vocab, d_model, max_len, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.tok = layers.Embedding(vocab,   d_model, name=\"tok_emb\")\n",
    "        self.pos = layers.Embedding(max_len, d_model, name=\"pos_emb\")\n",
    "\n",
    "    def call(self, tok_ids):                       # (B, L)\n",
    "        L = tf.shape(tok_ids)[1]\n",
    "        pos_ids = tf.range(L)                      # 0 … L-1\n",
    "        return self.tok(tok_ids) + self.pos(pos_ids)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Model\n",
    "# ------------------------------------------------------------------\n",
    "D_MODEL   = 8\n",
    "NUM_HEADS = 1\n",
    "KEY_DIM   = D_MODEL // NUM_HEADS\n",
    "\n",
    "inp      = layers.Input((SEQ_LEN + 1,), dtype=\"int32\", name=\"tokens\")\n",
    "emb      = PositionalEmbedding(VOCAB_SIZE, D_MODEL, SEQ_LEN + 1,\n",
    "                               name=\"embed\")(inp)\n",
    "\n",
    "attn_out, attn_scores = layers.MultiHeadAttention(\n",
    "        num_heads=NUM_HEADS,\n",
    "        key_dim=KEY_DIM,\n",
    "        output_shape=D_MODEL,\n",
    "        name=\"self_attn\")(emb, emb, return_attention_scores=True)\n",
    "\n",
    "x        = layers.LayerNormalization(epsilon=1e-6, name=\"ln\")(emb + attn_out)\n",
    "cls_vec  = x[:, 0, :]                           # [CLS]\n",
    "logits   = layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(cls_vec)\n",
    "\n",
    "model = Model(inp, logits, name=\"TinySelfAttention\")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Train\n",
    "# ------------------------------------------------------------------\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((tokens_np, labels_np))\n",
    "      .shuffle(NUM_SAMPLES)\n",
    "      .batch(16)\n",
    ")\n",
    "model.fit(train_ds, epochs=EPOCHS, verbose=0)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  Attention matrix for the first sample\n",
    "# ------------------------------------------------------------------\n",
    "attn_extractor = Model(inp, attn_scores)       # model that outputs only A\n",
    "A = attn_extractor.predict(tokens_np[:1])      # shape (1, 1, 7, 7)\n",
    "\n",
    "print(\"\\nAttention weights  (sample 0 · head 0):\")\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(A[0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "397c26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-0: [ 0 45 48  1  4  4 40]\n",
      "Token at pos-3: 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Model output for sample-0: 0.00041184496\n",
      "Sentence-idx: [ 0 16  5 42 43 32  2]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "0.99762386\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence-0:\", tokens_np[0])\n",
    "print(\"Token at pos-3:\", tokens_np[0, 3])\n",
    "pred = model.predict(tokens_np[:1])[0, 0]\n",
    "print(\"Model output for sample-0:\", pred)   # should be ≪ 0.5\n",
    "\n",
    "idx = np.where(labels_np == 1)[0][0]   # first positive sample\n",
    "print(\"Sentence-idx:\", tokens_np[idx])\n",
    "print(model.predict(tokens_np[idx:idx+1])[0, 0])  # should be ≫ 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311af02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}