{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21207\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('youtube+comedy+slam+preference+data/comedy_comparisons.train', header=None)\n",
    "\n",
    "# get all the unique values in the first column\n",
    "\n",
    "unique_values1 = df_train.iloc[:, 0].unique()\n",
    " # get all the unique values in the second column\n",
    "\n",
    "unique_values2 = df_train.iloc[:, 1].unique()\n",
    " \n",
    "unique_values_train = list(set(unique_values1) | set(unique_values2))\n",
    "\n",
    " \n",
    "\n",
    "df_test = pd.read_csv('youtube+comedy+slam+preference+data/comedy_comparisons.test', header=None)\n",
    "\n",
    "unique_values1 = df_test.iloc[:, 0].unique()\n",
    "# get all the unique values in the second column\n",
    "\n",
    "unique_values2 = df_test.iloc[:, 1].unique()\n",
    " \n",
    "unique_values_test = list(set(unique_values1) | set(unique_values2))\n",
    "\n",
    "unique_values =  list(set(unique_values_test + unique_values_train))\n",
    "\n",
    "print(len(unique_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing IDs: 9666\n",
      "Total Retrieved Videos: 11541\n",
      "Total Missing IDs: 9666\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Replace with your API key from Google Cloud Console\n",
    "API_KEY = \"AIzaSyAim0FVUvrcqmr2vxUBA0iQv-RIgRYC04c\"\n",
    "\n",
    "video_ids = unique_values \n",
    "\n",
    "def fetch_youtube_metadata(video_ids):\n",
    "    metadata = []\n",
    "    chunk_size = 50\n",
    "    missing_ids = []\n",
    "\n",
    "    for i in range(0, len(video_ids), chunk_size):\n",
    "        chunk = video_ids[i:i+chunk_size]\n",
    "        ids = \",\".join(chunk)\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/videos?part=snippet,statistics,contentDetails&id={ids}&key={API_KEY}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                missing_ids.extend(chunk)  # Log the chunk as failed\n",
    "                continue\n",
    "            \n",
    "            data = response.json()\n",
    "            for item in data.get(\"items\", []):\n",
    "                metadata.append({\n",
    "                    \"video_id\": item.get(\"id\"),\n",
    "                    \"title\": item[\"snippet\"].get(\"title\"),\n",
    "                    \"view_count\": item[\"statistics\"].get(\"viewCount\"),\n",
    "                    \"like_count\": item[\"statistics\"].get(\"likeCount\"),\n",
    "                    \"comment_count\": item[\"statistics\"].get(\"commentCount\"),\n",
    "                    \"duration\": item[\"contentDetails\"].get(\"duration\"),\n",
    "                })\n",
    "            \n",
    "            # Identify missing videos in this batch\n",
    "            retrieved_ids = [item[\"id\"] for item in data.get(\"items\", [])]\n",
    "            missing_ids.extend(set(chunk) - set(retrieved_ids))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "            missing_ids.extend(chunk)\n",
    "        \n",
    "        time.sleep(0.1)  # Avoid rate-limiting\n",
    "\n",
    "    print(f\"Total Missing IDs: {len(missing_ids)}\")\n",
    "    return metadata, missing_ids\n",
    "\n",
    "metadata, missing_ids = fetch_youtube_metadata(video_ids)\n",
    "\n",
    "print(f\"Total Retrieved Videos: {len(metadata)}\")\n",
    "print(f\"Total Missing IDs: {len(missing_ids)}\")\n",
    "# Save or print missing IDs for further analysis\n",
    "with open(\"missing_ids.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(missing_ids))\n",
    "\n",
    "data_for_df = {\n",
    "    \"video_id\": [],\n",
    "    \"title\": [],\n",
    "    \"view_count\": [],\n",
    "    \"like_count\": [],\n",
    "    \"comment_count\": [],\n",
    "    \"duration\": [],\n",
    "}\n",
    "\n",
    "# Print the results\n",
    "for video in metadata:\n",
    "    data_for_df[\"video_id\"].append(video[\"video_id\"])\n",
    "    data_for_df[\"title\"].append(video[\"title\"])\n",
    "    data_for_df[\"view_count\"].append(video[\"view_count\"])\n",
    "    data_for_df[\"like_count\"].append(video[\"like_count\"])\n",
    "    data_for_df[\"comment_count\"].append(video[\"comment_count\"])\n",
    "    data_for_df[\"duration\"].append(video[\"duration\"])\n",
    "\n",
    "df_metadata = pd.DataFrame(data_for_df)\n",
    "\n",
    "df_metadata.to_csv('youtube+comedy+slam+preference+data/comedy_comparisons_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11541\n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('youtube+comedy+slam+preference+data/comedy_comparisons_metadata.csv')\n",
    "df_metadata.describe()\n",
    "\n",
    "print(len(df_metadata['video_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278753\n",
      "912969\n",
      "225593\n",
      "77583\n"
     ]
    }
   ],
   "source": [
    "# restrict the preference to only those videos that are not missing\n",
    "\n",
    "df_train_restricted = df_train[(df_train.iloc[:, 0].isin(df_metadata['video_id'])) & (df_train.iloc[:, 1].isin(df_metadata['video_id']))]\n",
    "\n",
    "print(len(df_train_restricted))\n",
    "print(len(df_train))\n",
    "\n",
    "df_train_restricted.to_csv('youtube+comedy+slam+preference+data/train_restricted.csv', index=False, header=False)\n",
    "\n",
    "df_test_restricted = df_test[(df_test.iloc[:, 0].isin(df_metadata['video_id'])) & (df_test.iloc[:, 1].isin(df_metadata['video_id']))]\n",
    "\n",
    "print(len(df_test))\n",
    "\n",
    "print(len(df_test_restricted))\n",
    "\n",
    "df_test_restricted.head()\n",
    "df_test_restricted.to_csv('youtube+comedy+slam+preference+data/test_restricted.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video_id', 'title', 'view_count', 'like_count', 'comment_count', 'duration']\n"
     ]
    }
   ],
   "source": [
    "# read the csv file and convert it to a list of dictionaries with keys as the column names\n",
    "\n",
    "import csv\n",
    "\n",
    "metadata = []\n",
    "with open('youtube+comedy+slam+preference+data/comedy_comparisons_metadata.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    # get first row from the reader\n",
    "    header= next(reader)  # Skip the header row\n",
    "    print(header)\n",
    "    for row in reader:\n",
    "        metadata.append({\n",
    "            \"video_id\": row[0],\n",
    "            \"title\": row[1],\n",
    "            \"view_count\": row[2],\n",
    "            \"like_count\": row[3],\n",
    "            \"comment_count\": row[4],\n",
    "            \"duration\": row[5],\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0                                                  1           2  \\\n",
      "0     video_id                                              title  view_count   \n",
      "1  DE1-cD3pTkA                      Walker Texas Ranger clip LIVE         224   \n",
      "2  XZqSz_X-j8Y                Egg mcmuffin of a crappy commercial        1919   \n",
      "3  vzpD6OogahQ           Potter Puppet Pals: School Is For Losers    14958231   \n",
      "4  _OpzEHBDwQE  Very Funny Commercial  Think Beyond Your Ear (...       61696   \n",
      "\n",
      "            3              4         5  \n",
      "0  like_count  comment_count  duration  \n",
      "1           1              0     PT32S  \n",
      "2           7              3     PT44S  \n",
      "3       87806          11321     PT33S  \n",
      "4         179              2     PT38S  \n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('youtube+comedy+slam+preference+data/comedy_comparisons_metadata.csv', header=None)\n",
    "\n",
    "print(df_metadata.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' > 'a'\n",
    "\n",
    "'a' > ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_likes(metadata, video_id):\n",
    "    num =  [md for md in metadata if md['video_id'] == video_id][0].get('like_count', 0)  \n",
    "\n",
    "    return int(num) if num != '' else 0\n",
    "\n",
    "def get_num_comments(metadata, video_id):\n",
    "    num =  [md for md in metadata if md['video_id'] == video_id][0].get('comment_count', 0)  \n",
    "\n",
    "    return int(num) if num != '' else 0\n",
    "\n",
    "\n",
    "def get_num_views(metadata, video_id):\n",
    "    num =  [md for md in metadata if md['video_id'] == video_id][0].get('view_count', 0)  \n",
    "\n",
    "    return int(num) if num != '' else 0\n",
    "\n",
    "\n",
    "def get_likes_per_views(metadata, video_id):\n",
    "    num_views =  get_num_views(metadata, video_id)  \n",
    "    num_likes =  get_num_likes(metadata, video_id) \n",
    "\n",
    "    return num_likes/num_views if num_views != 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cand1': 'tG6CujNS6J0', 'cand2': 'mr8KrF8vNPM', 'winner': 1}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "comparisons = []\n",
    "with open('youtube+comedy+slam+preference+data/test_restricted.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        comparisons.append({\n",
    "            \"cand1\": row[0],\n",
    "            \"cand2\": row[1],\n",
    "            \"winner\": 1 if row[2] == \"left\" else 0,\n",
    "        })\n",
    "print(comparisons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent incorrect  0.49916863230346853\n",
      "Percent correct:  0.5008313676965315\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "for comparison in comparisons:\n",
    "    \n",
    "    if comparison['winner'] == 1 and get_num_likes(metadata, comparison['cand1']) > get_num_likes(metadata, comparison['cand2']): \n",
    "        num_correct += 1\n",
    "    elif comparison['winner'] == 0 and get_num_likes(metadata, comparison['cand2']) > get_num_likes(metadata, comparison['cand1']): \n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_incorrect += 1\n",
    "\n",
    "print(\"Percent incorrect \",  num_incorrect / len(comparisons))\n",
    "\n",
    "print(\"Percent correct: \", num_correct / len(comparisons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent incorrect  0.4999291081809159\n",
      "Percent correct:  0.500070891819084\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "for comparison in comparisons:\n",
    "    \n",
    "    if comparison['winner'] == 1 and get_num_likes(metadata, comparison['cand1']) > get_num_likes(metadata, comparison['cand2']): \n",
    "        num_correct += 1\n",
    "    elif comparison['winner'] == 0 and get_num_likes(metadata, comparison['cand2']) > get_num_likes(metadata, comparison['cand1']): \n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_incorrect += 1\n",
    "\n",
    "print(\"Percent incorrect \",  num_incorrect / len(comparisons))\n",
    "\n",
    "print(\"Percent correct: \", num_correct / len(comparisons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent incorrect  0.5271000090225951\n",
      "Percent correct:  0.47289999097740487\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "for comparison in comparisons:\n",
    "    \n",
    "    if comparison['winner'] == 1 and get_num_comments(metadata, comparison['cand1']) > get_num_comments(metadata, comparison['cand2']): \n",
    "        num_correct += 1\n",
    "    elif comparison['winner'] == 0 and get_num_comments(metadata, comparison['cand2']) > get_num_comments(metadata, comparison['cand1']): \n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_incorrect += 1\n",
    "\n",
    "print(\"Percent incorrect \",  num_incorrect / len(comparisons))\n",
    "\n",
    "print(\"Percent correct: \", num_correct / len(comparisons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent incorrect  0.5003544590954204\n",
      "Percent correct:  0.49964554090457963\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "for comparison in comparisons:\n",
    "    \n",
    "    if comparison['winner'] == 1 and get_num_views(metadata, comparison['cand1']) > get_num_views(metadata, comparison['cand2']): \n",
    "        num_correct += 1\n",
    "    elif comparison['winner'] == 0 and get_num_views(metadata, comparison['cand2']) > get_num_views(metadata, comparison['cand1']): \n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_incorrect += 1\n",
    "\n",
    "print(\"Percent incorrect \",  num_incorrect / len(comparisons))\n",
    "\n",
    "print(\"Percent correct: \", num_correct / len(comparisons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent incorrect  0.5003544590954204\n",
      "Percent correct:  0.49964554090457963\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "\n",
    "def eval_comparison(metadata, comparison, fnc):\n",
    "    if comparison['winner'] == 1 and fnc(metadata, comparison['cand1']) > fnc(metadata, comparison['cand2']): \n",
    "        return 1\n",
    "    elif comparison['winner'] == 0 and fnc(metadata, comparison['cand2']) > fnc(metadata, comparison['cand1']): \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "for comparison in comparisons:\n",
    "    \n",
    "    if eval_comparison(metadata, comparison, get_num_views):   \n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_incorrect += 1\n",
    "\n",
    "print(\"Percent incorrect \",  num_incorrect / len(comparisons))\n",
    "\n",
    "print(\"Percent correct: \", num_correct / len(comparisons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent incorrect  0.5099828570692033\n",
      "Percent correct:  0.4900171429307967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "\n",
    "for comparison in comparisons:\n",
    "    \n",
    "    if eval_comparison(metadata, comparison, get_likes_per_views):   \n",
    "        num_correct += 1\n",
    "    else:\n",
    "        num_incorrect += 1\n",
    "\n",
    "print(\"Percent incorrect \",  num_incorrect / len(comparisons))\n",
    "\n",
    "print(\"Percent correct: \", num_correct / len(comparisons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
